# ğŸ—ï¸ Architecture du projet Hackaton

Ce diagramme reprÃ©sente lâ€™architecture de notre projet de gÃ©nÃ©ration automatique de fiches clients.

```mermaid
graph TD  
    %% DÃ©finition des sous-groupes
    subgraph Frontend["ğŸ–¥ï¸ Interface Utilisateur"]
        A["ğŸ‘¤ Utilisateur"]
    end

    subgraph Backend["â˜ï¸ Services AWS"]
        C["ğŸ”„ API Gateway"]
        D["âš¡ Lambda Function"]
    end

    subgraph Storage["ğŸ“¦ Stockage des DonnÃ©es"]
        E["ğŸ’¾ AWS S3"]
        E1["ğŸ“Š Fichiers Excel"]
        E2["ğŸ“„ Fichiers PDF"]
        E3["ğŸ” Fichiers JSON"]
    end

    subgraph DataProcessing["ğŸ› ï¸ Traitement des DonnÃ©es"]
        F["ğŸ“Š Manipulation avec Pandas"]
        G["ğŸ“‘ GÃ©nÃ©ration PDF"]
        H["ğŸŒ RequÃªtes via SerpAPI"]
        I["ğŸ” Scraping avec BeautifulSoup"]
    end

    %% Flux principal
    A -->|"1. Envoi de la requÃªte"| C
    C -->|"2. Transmission de la requÃªte"| D
    D -->|"3. Lecture des donnÃ©es"| E
    D -->|"4. Lancement du scraping"| H
    H -->|"5. Extraction des donnÃ©es"| I
    D -->|"6. Traitement des donnÃ©es"| F
    F -->|"7. CrÃ©ation du document"| G
    G -->|"8. Enregistrement du PDF"| E2
    E -->|"9. Retour de la fiche"| A

    %% Connexions avec le stockage
    E1 -.-> E
    E2 -.-> E
    E3 -.-> E

    %% Styles amÃ©liorÃ©s pour plus de lisibilitÃ©
    classDef frontend fill:#FF5733,stroke:#8B0000,stroke-width:2px,color:white,font-size:14px;
    classDef backend fill:#3498DB,stroke:#1F618D,stroke-width:2px,color:white,font-size:14px;
    classDef storage fill:#F1C40F,stroke:#9A7D0A,stroke-width:2px,color:black,font-size:14px;
    classDef processing fill:#2ECC71,stroke:#196F3D,stroke-width:2px,color:white,font-size:14px;

    class A frontend;
    class C,D backend;
    class E,E1,E2,E3 storage;
    class F,G,H,I processing;

```
Explication du flux
Saisie du nom â†’ Lâ€™utilisateur entre le nom de la commune, du dÃ©partement ou de la rÃ©gion.  

Envoi de la requÃªte â†’ Streamlit transmet la requÃªte Ã  lâ€™API Gateway.  

Transmission de la requÃªte â†’ Lâ€™API Gateway dÃ©clenche la fonction Lambda.  

Lecture des donnÃ©es â†’ La fonction Lambda accÃ¨de aux fichiers stockÃ©s sur S3.  

Lancement du scraping â†’ Si les donnÃ©es ne sont pas disponibles, la recherche est lancÃ©e via SerpAPI.  

Extraction des donnÃ©es â†’ BeautifulSoup extrait les informations utiles depuis les sources en ligne.  

Traitement des donnÃ©es â†’ Pandas transforme et analyse les donnÃ©es rÃ©cupÃ©rÃ©es.  

CrÃ©ation du document â†’ Le fichier PDF de la fiche client est gÃ©nÃ©rÃ©.  

Enregistrement du PDF â†’ La fiche est sauvegardÃ©e dans AWS S3.  

Retour de la fiche â†’ La fiche est transmise Ã  lâ€™interface Streamlit.  

Affichage du rÃ©sultat â†’ Lâ€™utilisateur voit la fiche client gÃ©nÃ©rÃ©e  
